#!/usr/bin/env python3
import argparse
import datetime
import os
import re
import shutil
import sys

import yaml


# These files will be copied from the `rfc` repo to the handbook
ALLOWED_ASSET_FILE_EXTENSIONS = {
    '.jpg',
    '.md',  # only while some RFCs are split into subdocuments (not recommended)
    '.png',
    '.svg',
    '.webp',
}

# Don't change this or else we won't clean up old files correctly
AUTOGENERATED_MAGIC = 'Auto-generated by `handbook/scripts/aggregate-rfcs.py`'

AUTOGENERATED_COMMENT_TEMPLATE = f'# {AUTOGENERATED_MAGIC} from PLACEHOLDER - changes to this file will be overwritten'

OLD_RFC_NUMBER_IN_TITLE_REGEX = re.compile(r'RFC \d+\s*(-\s*)?')

LINK_REGEX = re.compile(r'\]\(\.\./(?P<slug>[^/]+)/README\.md\)')

RFC_STATE_TO_SPAN = {
    'open': '<span>',
    'in progress': '<span style="color: darkorange">',
    'approved': '<span style="color: darkgreen; font-weight: bold">',
    'declined': '<span style="color: darkred; opacity: 0.8">',
    'obsolete': '<span style="color: darkgray; opacity: 0.8">',
}
RFC_STATE_TO_TITLE_SPAN = {
    'open': '<span>',
    'in progress': '<span>',
    'approved': '<span>',
    'declined': '<span style="opacity: 0.3">',
    'obsolete': '<span style="opacity: 0.3">',
}


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('rfc_repo_dir', help='Path to Git clone of https://github.com/giantswarm/rfc')
    parser.add_argument('output_dir', help='Output path for rendered RFCs')
    args = parser.parse_args()

    rfcs = []

    for entry_name in sorted(os.listdir(args.rfc_repo_dir)):
        # Each RFC is expected in a top-level directory, containing the main file `README.md`
        rfc_dir = os.path.join(args.rfc_repo_dir, entry_name)
        readme_file_path = os.path.join(rfc_dir, 'README.md')
        if not os.path.exists(readme_file_path):
            continue

        print(f'Parsing RFC in {entry_name!r}')

        with open(readme_file_path, encoding='utf-8') as f:
            markdown_content = f.read()
        markdown_content_lines = markdown_content.splitlines()

        # Directory name is the article slug (i.e. fixed part in the handbook URL)
        slug = entry_name

        for title_line_index, line in enumerate(markdown_content_lines):
            if line.startswith('# '):
                title = line[len('# '):].strip()
                break
        else:
            raise RuntimeError(f'{readme_file_path}: Could not find title')

        # Some RFCs were titled after their GitHub PR number, but we didn't enforce such a numbering
        title = OLD_RFC_NUMBER_IN_TITLE_REGEX.sub('', title)

        for yaml_header_line_index_begin, line in enumerate(markdown_content_lines):
            if line.strip() == '---':
                break
        else:
            raise RuntimeError(f'{readme_file_path}: Could not find YAML header begin')
        for yaml_header_line_index_end, line in enumerate(markdown_content_lines[yaml_header_line_index_begin + 1:], start=yaml_header_line_index_begin + 1):
            if line.strip() == '---':
                break
        else:
            raise RuntimeError(f'{readme_file_path}: Could not find YAML header end')

        try:
            yaml_header = yaml.safe_load('\n'.join(markdown_content_lines[yaml_header_line_index_begin + 1:yaml_header_line_index_end]))
        except Exception as e:
            raise RuntimeError(f'{readme_file_path}: Failed to parse YAML header: {e}')
        try:
            if isinstance(yaml_header['creation_date'], datetime.date):
                creation_date = yaml_header['creation_date']
            else:
                creation_date = datetime.date.fromisoformat(yaml_header['creation_date'])
        except Exception:
            raise RuntimeError(f'{readme_file_path}: Invalid or missing field `creation_date` in YAML header, must be in format YYYY-MM-DD')

        try:
            state = yaml_header['state']
        except Exception:
            raise RuntimeError(f'{readme_file_path}: Missing field `state` in YAML header')
        if state not in RFC_STATE_TO_SPAN or state not in RFC_STATE_TO_TITLE_SPAN:
            raise RuntimeError(f'{readme_file_path}: Invalid state - must be one of {{{", ".join(RFC_STATE_TO_SPAN)}}}')

        # Trim whitespace
        for i in range(len(markdown_content_lines)):
            markdown_content_lines[i] = markdown_content_lines[i].rstrip()

        # Assume the article starts with the H1 heading (= title). Strip off that title (since Hugo inserts it) and also
        # the YAML header which we don't need in the output file, as we insert a Hugo-related YAML header instead.
        markdown_content_without_title = '\n'.join(markdown_content_lines[title_line_index + 1:]).lstrip().rstrip('\n') + '\n'

        # Fix links between RFCs
        markdown_content_without_title = LINK_REGEX.sub(lambda m: ']({{< relref "/docs/rfcs/%s/" >}})' % m['slug'], markdown_content_without_title)

        rfcs.append({
            'markdown_content_without_title': markdown_content_without_title,
            'creation_date': creation_date,
            'rfc_dir': rfc_dir,
            'slug': slug,
            'state': state,
            'state_span': RFC_STATE_TO_SPAN[state],
            'title': title,
            'title_span': RFC_STATE_TO_TITLE_SPAN[state],
        })

    output_index_file_path = os.path.join(args.output_dir, '_index.md')
    if not os.path.exists(output_index_file_path):
        raise RuntimeError(f'Invalid output directory {args.output_dir!r}, expected `_index.md` in that directory')

    # First capture which old content to delete in order to be idempotent
    files_to_delete = set()
    for root, dirs, files in os.walk(args.output_dir):
        for filename in files:
            file_path = os.path.join(root, filename)
            with open(file_path, encoding='utf-8', errors='replace') as f:
                content = f.read()
            if AUTOGENERATED_MAGIC in content:
                files_to_delete.add(os.path.normpath(file_path))

    # Create table of RFCs
    table = (
        '| Created (newest first) | Title | State |\n'
        '| ---------------------- | ----- | ----- |\n'
    )
    for rfc in sorted(rfcs, key=lambda rfc: (-(rfc['creation_date'] - datetime.date(1970, 1, 1)).total_seconds(), rfc['title'])):
        table += f'| {rfc["creation_date"].isoformat()} | {rfc["title_span"]}[{rfc["title"]}](./{rfc["slug"]})</span> | {rfc["state_span"]}{rfc["state"]}</span> |\n'
    with open(output_index_file_path, 'r+', encoding='utf-8') as f:
        content = f.read()

        regex = re.compile(r'(<!-- AUTOGENERATED RFC TABLE BEGIN -->\n).*(<!-- AUTOGENERATED RFC TABLE END -->\n)', flags=re.DOTALL)
        if not regex.search(content):
            raise RuntimeError(f'Did not find placeholders for RFC table in {output_index_file_path!r}')
        new_content = regex.sub(lambda m: m[1] + table.rstrip('\n') + '\n' + m[2], content)

        f.seek(0)
        f.write(new_content)
        f.truncate()

    # Create Markdown file per RFC
    for rfc in sorted(rfcs, key=lambda rfc: rfc['creation_date']):
        rfc_output_dir = os.path.join(args.output_dir, rfc['slug'])
        if not os.path.isdir(rfc_output_dir):
            os.mkdir(rfc_output_dir)

        markdown_output_file_path = os.path.join(rfc_output_dir, f'_index.md')
        markdown_content = (
            '---\n'
            + AUTOGENERATED_COMMENT_TEMPLATE.replace(
                'PLACEHOLDER',
                f'https://github.com/giantswarm/rfc/tree/main/{rfc["slug"]}')
            + '\n'
            + yaml.dump({'title': rfc['title']})
            + 'toc_hide: true\n'
            + 'hide_summary: true\n'
            + '---\n'
            + '\n'
            + rfc['markdown_content_without_title']
        )
        print(f'Updating file {markdown_output_file_path!r}')
        with open(markdown_output_file_path, 'w', encoding='utf-8') as out:
            out.write(markdown_content)

        files_to_delete.discard(os.path.normpath(markdown_output_file_path))

        # Also copy content files. Some RFCs are even separated into multiple Markdown files (not recommended, but let's
        # support it while we have that case).
        for filename in os.listdir(rfc['rfc_dir']):
            if filename == 'README.md':
                continue

            file_path = os.path.join(rfc['rfc_dir'], filename)
            if not os.path.isfile(file_path):
                continue

            _, file_extension = os.path.splitext(filename)
            if file_extension not in ALLOWED_ASSET_FILE_EXTENSIONS:
                print(f'{rfc["rfc_dir"]}: Ignoring file {filename!r}')
                continue

            # Note that we don't delete/reconcile old files in the output directory here.
            # We can add that feature if cleanup is ever needed.
            print(f'{rfc["rfc_dir"]}: Copying asset file {filename!r}')
            shutil.copy(file_path, os.path.join(rfc_output_dir, filename))

    for file_path in files_to_delete:
        print(f'Deleting old file {file_path!r}')
        os.remove(file_path)


if __name__ == '__main__':
    sys.exit(main())
